{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40c80180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85daf76f",
   "metadata": {},
   "source": [
    "# ======== Classification Models ========"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87c197b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Simple logistic regression implementation.\"\"\"\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    \n",
    "    model = LogisticRegression(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Logistic Regression Accuracy: {accuracy:.4f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74875f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_classifier(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Simple decision tree classifier implementation.\"\"\"\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    \n",
    "    model = DecisionTreeClassifier(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Decision Tree Classifier Accuracy: {accuracy:.4f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26c5358c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_classifier(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Simple random forest classifier implementation.\"\"\"\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Random Forest Classifier Accuracy: {accuracy:.4f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dd77798",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_classifier(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Support Vector Machine classifier implementation.\"\"\"\n",
    "    from sklearn.svm import SVC\n",
    "    \n",
    "    model = SVC(kernel='rbf', random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"SVM Classifier Accuracy: {accuracy:.4f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd221153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_classifier(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"K-Nearest Neighbors classifier implementation.\"\"\"\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    \n",
    "    model = KNeighborsClassifier(n_neighbors=5)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"KNN Classifier Accuracy: {accuracy:.4f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "676ca8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Gaussian Naive Bayes classifier implementation.\"\"\"\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    \n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Naive Bayes Accuracy: {accuracy:.4f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ec9d543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_boosting_classifier(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Gradient Boosting classifier implementation.\"\"\"\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    \n",
    "    model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Gradient Boosting Classifier Accuracy: {accuracy:.4f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0b2b14",
   "metadata": {},
   "source": [
    "# ======== Regression Models ========"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "663b6a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Simple linear regression implementation.\"\"\"\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Linear Regression MSE: {mse:.4f}, R²: {r2:.4f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ff5ec09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def decision_tree_regressor(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Simple decision tree regressor implementation.\"\"\"\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "    \n",
    "    model = DecisionTreeRegressor(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Decision Tree Regressor MSE: {mse:.4f}, R²: {r2:.4f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf24c39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_regressor(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Simple random forest regressor implementation.\"\"\"\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    \n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Random Forest Regressor MSE: {mse:.4f}, R²: {r2:.4f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b95c41d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_regressor(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Support Vector Machine regressor implementation.\"\"\"\n",
    "    from sklearn.svm import SVR\n",
    "    \n",
    "    model = SVR(kernel='rbf')\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"SVM Regressor MSE: {mse:.4f}, R²: {r2:.4f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c05f625",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_boosting_regressor(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Gradient Boosting regressor implementation.\"\"\"\n",
    "    from sklearn.ensemble import GradientBoostingRegressor\n",
    "    \n",
    "    model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Gradient Boosting Regressor MSE: {mse:.4f}, R²: {r2:.4f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b22a5b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_regression(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Lasso Regression implementation.\"\"\"\n",
    "    from sklearn.linear_model import Lasso\n",
    "    \n",
    "    model = Lasso(alpha=1.0, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Lasso Regression MSE: {mse:.4f}, R²: {r2:.4f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4761b30",
   "metadata": {},
   "source": [
    "# ======== Example usage ========"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa1b35dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_classification_example():\n",
    "    \"\"\"Run a simple classification example using the Iris dataset.\"\"\"\n",
    "    from sklearn.datasets import load_iris\n",
    "    \n",
    "    # Load data\n",
    "    iris = load_iris()\n",
    "    X, y = iris.data, iris.target\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # Train and evaluate models\n",
    "    print(\"===== Classification Models on Iris Dataset =====\")\n",
    "    logistic_regression(X_train, X_test, y_train, y_test)\n",
    "    decision_tree_classifier(X_train, X_test, y_train, y_test)\n",
    "    random_forest_classifier(X_train, X_test, y_train, y_test)\n",
    "    svm_classifier(X_train, X_test, y_train, y_test)\n",
    "    knn_classifier(X_train, X_test, y_train, y_test)\n",
    "    naive_bayes(X_train, X_test, y_train, y_test)\n",
    "    gradient_boosting_classifier(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df1763fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_regression_example():\n",
    "    \"\"\"Run a simple regression example using the Boston Housing dataset.\"\"\"\n",
    "    from sklearn.datasets import fetch_california_housing\n",
    "    \n",
    "    # Load data\n",
    "    housing = fetch_california_housing()\n",
    "    X, y = housing.data, housing.target\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # Train and evaluate models\n",
    "    print(\"\\n===== Regression Models on California Housing Dataset =====\")\n",
    "    linear_regression(X_train, X_test, y_train, y_test)\n",
    "    decision_tree_regressor(X_train, X_test, y_train, y_test)\n",
    "    random_forest_regressor(X_train, X_test, y_train, y_test)\n",
    "    svm_regressor(X_train, X_test, y_train, y_test)\n",
    "    gradient_boosting_regressor(X_train, X_test, y_train, y_test)\n",
    "    lasso_regression(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53e4d5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Classification Models on Iris Dataset =====\n",
      "Logistic Regression Accuracy: 1.0000\n",
      "Decision Tree Classifier Accuracy: 1.0000\n",
      "Random Forest Classifier Accuracy: 1.0000\n",
      "SVM Classifier Accuracy: 1.0000\n",
      "KNN Classifier Accuracy: 1.0000\n",
      "Naive Bayes Accuracy: 1.0000\n",
      "Gradient Boosting Classifier Accuracy: 1.0000\n",
      "\n",
      "===== Regression Models on California Housing Dataset =====\n",
      "Linear Regression MSE: 0.5559, R²: 0.5758\n",
      "Decision Tree Regressor MSE: 0.4940, R²: 0.6230\n",
      "Random Forest Regressor MSE: 0.2552, R²: 0.8053\n",
      "SVM Regressor MSE: 0.3570, R²: 0.7276\n",
      "Gradient Boosting Regressor MSE: 0.2940, R²: 0.7756\n",
      "Lasso Regression MSE: 1.3107, R²: -0.0002\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run_classification_example()\n",
    "    run_regression_example()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
