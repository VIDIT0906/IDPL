{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50ae3b9a",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebbd3a7",
   "metadata": {},
   "source": [
    "h( x ) = sigmoid( wx + b )\n",
    "\n",
    "Here, w is the weight vector.  \n",
    "x is the feature vector.   \n",
    "b is the bias.\n",
    "\n",
    "sigmoid( z ) = 1 / ( 1 + e( - z ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19d60770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# to compare our model's accuracy with sklearn model \n",
    "from sklearn.linear_model import LogisticRegression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4d3e484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression \n",
    "class LogitRegression() : \n",
    "\tdef __init__( self, learning_rate, iterations ) :\t\t \n",
    "\t\tself.learning_rate = learning_rate\t\t \n",
    "\t\tself.iterations = iterations \n",
    "\t\t\n",
    "\t# Function for model training\t \n",
    "\tdef fit( self, X, Y ) :\t\t \n",
    "\t\t# no_of_training_examples, no_of_features\t\t \n",
    "\t\tself.m, self.n = X.shape\t\t \n",
    "\t\t# weight initialization\t\t \n",
    "\t\tself.W = np.zeros( self.n )\t\t \n",
    "\t\tself.b = 0\t\t\n",
    "\t\tself.X = X\t\t \n",
    "\t\tself.Y = Y \n",
    "\t\t\n",
    "\t\t# gradient descent learning \n",
    "\t\t\t\t\n",
    "\t\tfor i in range( self.iterations ) :\t\t\t \n",
    "\t\t\tself.update_weights()\t\t\t \n",
    "\t\treturn self\n",
    "\t\n",
    "\t# Helper function to update weights in gradient descent \n",
    "\t\n",
    "\tdef update_weights( self ) :\t\t \n",
    "\t\tA = 1 / ( 1 + np.exp( - ( self.X.dot( self.W ) + self.b ) ) ) \n",
    "\t\t\n",
    "\t\t# calculate gradients\t\t \n",
    "\t\ttmp = ( A - self.Y.T )\t\t \n",
    "\t\ttmp = np.reshape( tmp, self.m )\t\t \n",
    "\t\tdW = np.dot( self.X.T, tmp ) / self.m\t\t \n",
    "\t\tdb = np.sum( tmp ) / self.m \n",
    "\t\t\n",
    "\t\t# update weights\t \n",
    "\t\tself.W = self.W - self.learning_rate * dW\t \n",
    "\t\tself.b = self.b - self.learning_rate * db \n",
    "\t\t\n",
    "\t\treturn self\n",
    "\t\n",
    "\t# Hypothetical function h( x ) \n",
    "\t\n",
    "\tdef predict( self, X ) :\t \n",
    "\t\tZ = 1 / ( 1 + np.exp( - ( X.dot( self.W ) + self.b ) ) )\t\t \n",
    "\t\tY = np.where( Z > 0.5, 1, 0 )\t\t \n",
    "\t\treturn Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfaca612",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main() : \n",
    "\t\n",
    "\t# Importing dataset\t \n",
    "\tdf = pd.read_csv( \"diabetes.csv\" ) \n",
    "\tX = df.iloc[:,:-1].values \n",
    "\tY = df.iloc[:,-1:].values \n",
    "\t\n",
    "\t# Splitting dataset into train and test set \n",
    "\tX_train, X_test, Y_train, Y_test = train_test_split( \n",
    "\tX, Y, test_size = 1/3, random_state = 0 ) \n",
    "\t\n",
    "\t# Model training\t \n",
    "\tmodel = LogitRegression( learning_rate = 0.01, iterations = 1000 ) \n",
    "\t\n",
    "\tmodel.fit( X_train, Y_train )\t \n",
    "\tmodel1 = LogisticRegression()\t \n",
    "\tmodel1.fit( X_train, Y_train) \n",
    "\t\n",
    "\t# Prediction on test set \n",
    "\tY_pred = model.predict( X_test )\t \n",
    "\tY_pred1 = model1.predict( X_test ) \n",
    "\t\n",
    "\t# measure performance\t \n",
    "\tcorrectly_classified = 0\t\n",
    "\tcorrectly_classified1 = 0\n",
    "\t\n",
    "\t# counter\t \n",
    "\tcount = 0\t\n",
    "\tfor count in range( np.size( Y_pred ) ) : \n",
    "\t\t\n",
    "\t\tif Y_test[count] == Y_pred[count] :\t\t\t \n",
    "\t\t\tcorrectly_classified = correctly_classified + 1\n",
    "\t\t\n",
    "\t\tif Y_test[count] == Y_pred1[count] :\t\t\t \n",
    "\t\t\tcorrectly_classified1 = correctly_classified1 + 1\n",
    "\t\t\t\n",
    "\t\tcount = count + 1\n",
    "\t\t\n",
    "\tprint( \"Accuracy on test set by our model     :\", ( \n",
    "\tcorrectly_classified / count ) * 100 ) \n",
    "\tprint( \"Accuracy on test set by sklearn model :\", ( \n",
    "\tcorrectly_classified1 / count ) * 100 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33ed947a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set by our model     : 66.796875\n",
      "Accuracy on test set by sklearn model : 80.46875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\acer\\anaconda3\\envs\\ML\\lib\\site-packages\\sklearn\\utils\\validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\acer\\anaconda3\\envs\\ML\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\" :\t \n",
    "\tmain()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
